
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Sequential Recommender Quick Start &#8212; &lt;h1 style=&#34;font-size:1.7em;text-align:center;color:#FF5733&#34;&gt;Recommenders&lt;/h1&gt;</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/tabs.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title"><h1 style="font-size:1.7em;text-align:center;color:#FF5733">Recommenders</h1></h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption" role="heading">
 <span class="caption-text">
  Quick Start
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="als_movielens.html">
   Running ALS on MovieLens (PySpark)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ncf_movielens.html">
   Neural Collaborative Filtering on MovieLens dataset.
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Deep Dive
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../02_model_collaborative_filtering/als_deep_dive.html">
   Spark Collaborative Filtering (ALS) Deep Dive
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../02_model_collaborative_filtering/baseline_deep_dive.html">
   Estimating Baseline Performance
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  API Documentation
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../source/datasets.html">
   Dataset module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../source/evaluation.html">
   Evaluation module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../source/models.html">
   Recommender algorithms module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../source/tuning.html">
   Hyperparameter tuning module
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../source/utils.html">
   Common utilities module
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/examples/00_quick_start/sequential_recsys_amazondataset.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/microsoft/recommenders"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/microsoft/recommenders/issues/new?title=Issue%20on%20page%20%2Fexamples/00_quick_start/sequential_recsys_amazondataset.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/microsoft/recommenders/main?urlpath=tree/docs/examples/00_quick_start/sequential_recsys_amazondataset.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#example-sli-rec-adaptive-user-modeling-with-long-and-short-term-preferences-for-personailzed-recommendation">
   Example: SLi_Rec : Adaptive User Modeling with Long and Short-Term Preferences for Personailzed Recommendation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#global-settings-and-imports">
   0. Global Settings and Imports
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters">
     Parameters
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#input-data-format">
   1. Input data format
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#amazon-dataset">
     Amazon dataset
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#prepare-hyper-parameters">
       1.1 Prepare hyper-parameters
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#create-data-loader">
       1.2 Create data loader
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-model">
   2. Create model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-model">
     2.1 Train model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluate-model">
     2.2  Evaluate model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#running-models-with-large-dataset">
     2.3  Running models with large dataset
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#online-serving">
   3. Online serving
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reference">
   Reference
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><i>Copyright (c) Microsoft Corporation. All rights reserved.</i></p>
<p><i>Licensed under the MIT License.</i></p>
<div class="tex2jax_ignore mathjax_ignore section" id="sequential-recommender-quick-start">
<h1>Sequential Recommender Quick Start<a class="headerlink" href="#sequential-recommender-quick-start" title="Permalink to this headline">¶</a></h1>
<div class="section" id="example-sli-rec-adaptive-user-modeling-with-long-and-short-term-preferences-for-personailzed-recommendation">
<h2>Example: SLi_Rec : Adaptive User Modeling with Long and Short-Term Preferences for Personailzed Recommendation<a class="headerlink" href="#example-sli-rec-adaptive-user-modeling-with-long-and-short-term-preferences-for-personailzed-recommendation" title="Permalink to this headline">¶</a></h2>
<p>Unlike a general recommender such as Matrix Factorization or xDeepFM (in the repo) which doesn’t consider the order of the user’s activities, sequential recommender systems take the sequence of the user behaviors as context and the goal is to predict the items that the user will interact in a short time (in an extreme case, the item that the user will interact next).</p>
<p>This notebook aims to give you a quick example of how to train a sequential model based on a public Amazon dataset. Currently, we can support NextItNet [4], GRU4Rec [2], Caser [3], A2SVD [1], SLi_Rec [1], and SUM [5]. Without loss of generality, this notebook takes <a class="reference external" href="https://www.microsoft.com/en-us/research/uploads/prod/2019/07/IJCAI19-ready_v1.pdf">SLi_Rec model</a> for example.
SLi_Rec [1] is a deep learning-based model aims at capturing both long and short-term user preferences for precise recommender systems. To summarize, SLi_Rec has the following key properties:</p>
<ul class="simple">
<li><p>It adopts the attentive “Asymmetric-SVD” paradigm for long-term modeling;</p></li>
<li><p>It takes both time irregularity and semantic irregularity into consideration by modifying the gating logic in LSTM.</p></li>
<li><p>It uses an attention mechanism to dynamic fuse the long-term component and short-term component.</p></li>
</ul>
<p>In this notebook, we test SLi_Rec on a subset of the public dataset: <a class="reference external" href="http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Movies_and_TV_5.json.gz">Amazon_reviews</a> and <a class="reference external" href="http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_Movies_and_TV.json.gz">Amazon_metadata</a></p>
<p>This notebook is well tested under TF 1.15.0.</p>
</div>
<div class="section" id="global-settings-and-imports">
<h2>0. Global Settings and Imports<a class="headerlink" href="#global-settings-and-imports" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">papermill</span> <span class="k">as</span> <span class="nn">pm</span>
<span class="kn">import</span> <span class="nn">scrapbook</span> <span class="k">as</span> <span class="nn">sb</span>
<span class="kn">from</span> <span class="nn">tempfile</span> <span class="kn">import</span> <span class="n">TemporaryDirectory</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="s1">&#39;ERROR&#39;</span><span class="p">)</span> <span class="c1"># only show error messages</span>

<span class="kn">from</span> <span class="nn">recommenders.utils.timer</span> <span class="kn">import</span> <span class="n">Timer</span>
<span class="kn">from</span> <span class="nn">recommenders.utils.constants</span> <span class="kn">import</span> <span class="n">SEED</span>
<span class="kn">from</span> <span class="nn">recommenders.models.deeprec.deeprec_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">prepare_hparams</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">recommenders.datasets.amazon_reviews</span> <span class="kn">import</span> <span class="n">download_and_extract</span><span class="p">,</span> <span class="n">data_preprocessing</span>
<span class="kn">from</span> <span class="nn">recommenders.datasets.download_utils</span> <span class="kn">import</span> <span class="n">maybe_download</span>


<span class="kn">from</span> <span class="nn">recommenders.models.deeprec.models.sequential.sli_rec</span> <span class="kn">import</span> <span class="n">SLI_RECModel</span> <span class="k">as</span> <span class="n">SeqModel</span>
<span class="c1">####  to use the other model, use one of the following lines:</span>
<span class="c1"># from recommenders.models.deeprec.models.sequential.asvd import A2SVDModel as SeqModel</span>
<span class="c1"># from recommenders.models.deeprec.models.sequential.caser import CaserModel as SeqModel</span>
<span class="c1"># from recommenders.models.deeprec.models.sequential.gru4rec import GRU4RecModel as SeqModel</span>
<span class="c1"># from recommenders.models.deeprec.models.sequential.sum import SUMModel as SeqModel</span>

<span class="c1">#from recommenders.models.deeprec.models.sequential.nextitnet import NextItNetModel</span>

<span class="kn">from</span> <span class="nn">recommenders.models.deeprec.io.sequential_iterator</span> <span class="kn">import</span> <span class="n">SequentialIterator</span>
<span class="c1">#from recommenders.models.deeprec.io.nextitnet_iterator import NextItNetIterator</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;System version: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tensorflow version: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>System version: 3.6.11 | packaged by conda-forge | (default, Aug  5 2020, 20:09:42) 
[GCC 7.5.0]
Tensorflow version: 1.15.2
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##  ATTENTION: change to the corresponding config file, e.g., caser.yaml for CaserModel, sum.yaml for SUMModel</span>
<span class="n">yaml_file</span> <span class="o">=</span> <span class="s1">&#39;../../recommenders/models/deeprec/config/sli_rec.yaml&#39;</span>  
</pre></div>
</div>
</div>
</div>
<div class="section" id="parameters">
<h3>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_parameters docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">400</span>
<span class="n">RANDOM_SEED</span> <span class="o">=</span> <span class="n">SEED</span>  <span class="c1"># Set None for non-deterministic result</span>

<span class="n">data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;tests&quot;</span><span class="p">,</span> <span class="s2">&quot;resources&quot;</span><span class="p">,</span> <span class="s2">&quot;deeprec&quot;</span><span class="p">,</span> <span class="s2">&quot;slirec&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="input-data-format">
<h2>1. Input data format<a class="headerlink" href="#input-data-format" title="Permalink to this headline">¶</a></h2>
<p>The input data contains 8 columns, i.e.,   <code class="docutils literal notranslate"><span class="pre">&lt;label&gt;</span> <span class="pre">&lt;user_id&gt;</span> <span class="pre">&lt;item_id&gt;</span> <span class="pre">&lt;category_id&gt;</span> <span class="pre">&lt;timestamp&gt;</span> <span class="pre">&lt;history_item_ids&gt;</span> <span class="pre">&lt;history_cateory_ids&gt;</span> <span class="pre">&lt;hitory_timestamp&gt;</span></code>  columns are seperated by <code class="docutils literal notranslate"><span class="pre">&quot;\t&quot;</span></code>.  item_id and category_id denote the target item and category, which means that for this instance, we want to guess whether user user_id will interact with item_id at timestamp. <code class="docutils literal notranslate"><span class="pre">&lt;history_*&gt;</span></code> columns record the user behavior list up to <code class="docutils literal notranslate"><span class="pre">&lt;timestamp&gt;</span></code>, elements are separated by commas.  <code class="docutils literal notranslate"><span class="pre">&lt;label&gt;</span></code> is a binary value with 1 for positive instances and 0 for negative instances.  One example for an instance is:</p>
<p><code class="docutils literal notranslate"><span class="pre">1</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">A1QQ86H5M2LVW2</span>&#160; <span class="pre">B0059XTU1S</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">Movies</span>&#160; <span class="pre">1377561600</span>&#160;&#160;&#160;&#160;&#160; <span class="pre">B002ZG97WE,B004IK30PA,B000BNX3AU,B0017ANB08,B005LAIHW2</span>&#160; <span class="pre">Movies,Movies,Movies,Movies,Movies</span>&#160;&#160; <span class="pre">1304294400,1304812800,1315785600,1316304000,1356998400</span></code></p>
<p>In data preprocessing stage, we have a script to generate some ID mapping dictionaries, so user_id, item_id and category_id will be mapped into interager index starting from 1. And you need to tell the input iterator where is the ID mapping files are. (For example, in the next section, we have some mapping files like user_vocab, item_vocab, and cate_vocab).  The data preprocessing script is at <span class="xref myst">recommenders/dataset/amazon_reviews.py</span>, you need to call the <code class="docutils literal notranslate"><span class="pre">_create_vocab(train_file,</span> <span class="pre">user_vocab,</span> <span class="pre">item_vocab,</span> <span class="pre">cate_vocab)</span></code> function. Note that ID vocabulary only creates from the train_file, so the new IDs in valid_file or test_file will be regarded as unknown IDs and assigned with a defualt 0 index.</p>
<p>Only the SLi_Rec model is time-aware. For the other models, you can just pad some meaningless timestamp in the data files to fill up the format, the models will ignore these columns.</p>
<p>We use Softmax to the loss function. In training and evalution stage, we group 1 positive instance with num_ngs negative instances. Pair-wise ranking can be regarded as a special case of Softmax ranking, where num_ngs is set to 1.</p>
<p>More specifically,  for training and evalation, you need to organize the data file such that each one positive instance is followd by num_ngs negative instances. Our program will take 1+num_ngs lines as a unit for Softmax calculation. num_ngs is a parameter you need to pass to the <code class="docutils literal notranslate"><span class="pre">prepare_hparams</span></code>, <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">run_eval</span></code> function. <code class="docutils literal notranslate"><span class="pre">train_num_ngs</span></code> in <code class="docutils literal notranslate"><span class="pre">prepare_hparams</span></code> denotes the number of negative instances for training, where a recommended number is 4. <code class="docutils literal notranslate"><span class="pre">valid_num_ngs</span></code> and <code class="docutils literal notranslate"><span class="pre">num_ngs</span></code> in <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">run_eval</span></code> denote the number in evalution. In evaluation, the model calculates metrics among the 1+num_ngs instances. For the <code class="docutils literal notranslate"><span class="pre">predict</span></code> function, since we only need to calcuate a socre for each individual instance, there is no need for num_ngs setting.  More details and examples will be provided in the following sections.</p>
<p>For training stage, if you don’t want to prepare negative instances, you can just provide positive instances and set the parameter <code class="docutils literal notranslate"><span class="pre">need_sample=True,</span> <span class="pre">train_num_ngs=train_num_ngs</span></code> for function <code class="docutils literal notranslate"><span class="pre">prepare_hparams</span></code>, our model will dynamicly sample <code class="docutils literal notranslate"><span class="pre">train_num_ngs</span></code> instances as negative samples in each mini batch.</p>
<div class="section" id="amazon-dataset">
<h3>Amazon dataset<a class="headerlink" href="#amazon-dataset" title="Permalink to this headline">¶</a></h3>
<p>Now let’s start with a public dataset containing product reviews and metadata from Amazon, which is widely used as a benchmark dataset in recommemdation systems field.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># for test</span>
<span class="n">train_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;train_data&#39;</span><span class="p">)</span>
<span class="n">valid_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;valid_data&#39;</span><span class="p">)</span>
<span class="n">test_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;test_data&#39;</span><span class="p">)</span>
<span class="n">user_vocab</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;user_vocab.pkl&#39;</span><span class="p">)</span>
<span class="n">item_vocab</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;item_vocab.pkl&#39;</span><span class="p">)</span>
<span class="n">cate_vocab</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;category_vocab.pkl&#39;</span><span class="p">)</span>
<span class="n">output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;output.txt&#39;</span><span class="p">)</span>

<span class="n">reviews_name</span> <span class="o">=</span> <span class="s1">&#39;reviews_Movies_and_TV_5.json&#39;</span>
<span class="n">meta_name</span> <span class="o">=</span> <span class="s1">&#39;meta_Movies_and_TV.json&#39;</span>
<span class="n">reviews_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">reviews_name</span><span class="p">)</span>
<span class="n">meta_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">meta_name</span><span class="p">)</span>
<span class="n">train_num_ngs</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># number of negative instances with a positive instance for training</span>
<span class="n">valid_num_ngs</span> <span class="o">=</span> <span class="mi">4</span> <span class="c1"># number of negative instances with a positive instance for validation</span>
<span class="n">test_num_ngs</span> <span class="o">=</span> <span class="mi">9</span> <span class="c1"># number of negative instances with a positive instance for testing</span>
<span class="n">sample_rate</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="c1"># sample a small item set for training and testing here for fast example</span>

<span class="n">input_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">reviews_file</span><span class="p">,</span> <span class="n">meta_file</span><span class="p">,</span> <span class="n">train_file</span><span class="p">,</span> <span class="n">valid_file</span><span class="p">,</span> <span class="n">test_file</span><span class="p">,</span> <span class="n">user_vocab</span><span class="p">,</span> <span class="n">item_vocab</span><span class="p">,</span> <span class="n">cate_vocab</span><span class="p">]</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">train_file</span><span class="p">):</span>
    <span class="n">download_and_extract</span><span class="p">(</span><span class="n">reviews_name</span><span class="p">,</span> <span class="n">reviews_file</span><span class="p">)</span>
    <span class="n">download_and_extract</span><span class="p">(</span><span class="n">meta_name</span><span class="p">,</span> <span class="n">meta_file</span><span class="p">)</span>
    <span class="n">data_preprocessing</span><span class="p">(</span><span class="o">*</span><span class="n">input_files</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">,</span> <span class="n">valid_num_ngs</span><span class="o">=</span><span class="n">valid_num_ngs</span><span class="p">,</span> <span class="n">test_num_ngs</span><span class="o">=</span><span class="n">test_num_ngs</span><span class="p">)</span>
    <span class="c1">#### uncomment this for the NextItNet model, because it does not need to unfold the user history</span>
    <span class="c1"># data_preprocessing(*input_files, sample_rate=sample_rate, valid_num_ngs=valid_num_ngs, test_num_ngs=test_num_ngs, is_history_expanding=False)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="prepare-hyper-parameters">
<h4>1.1 Prepare hyper-parameters<a class="headerlink" href="#prepare-hyper-parameters" title="Permalink to this headline">¶</a></h4>
<p>prepare_hparams() will create a full set of hyper-parameters for model training, such as learning rate, feature number, and dropout ratio. We can put those parameters in a yaml file (a complete list of parameters can be found under our config folder) , or pass parameters as the function’s parameters (which will overwrite yaml settings).</p>
<p>Parameters hints: <br>
<code class="docutils literal notranslate"><span class="pre">need_sample</span></code> controls whether to perform dynamic negative sampling in mini-batch.
<code class="docutils literal notranslate"><span class="pre">train_num_ngs</span></code> indicates how many negative instances followed by one positive instances.  <br>
Examples: <br>
(1) <code class="docutils literal notranslate"><span class="pre">need_sample=True</span> <span class="pre">and</span> <span class="pre">train_num_ngs=4</span></code>:  There are only positive instances in your training file. Our model will dynamically sample 4 negative instances for each positive instances in mini-batch. Note that if need_sample is set to True, train_num_ngs should be greater than zero. <br>
(2) <code class="docutils literal notranslate"><span class="pre">need_sample=False</span> <span class="pre">and</span> <span class="pre">train_num_ngs=4</span></code>: In your training file, each one positive line is followed by 4 negative lines. Note that if need_sample is set to False, you must provide a traiing file with negative instances, and train_num_ngs should match the number of negative number in your training file.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### NOTE:  </span>
<span class="c1">### remember to use `_create_vocab(train_file, user_vocab, item_vocab, cate_vocab)` to generate the user_vocab, item_vocab and cate_vocab files, if you are using your own dataset rather than using our demo Amazon dataset.</span>
<span class="n">hparams</span> <span class="o">=</span> <span class="n">prepare_hparams</span><span class="p">(</span><span class="n">yaml_file</span><span class="p">,</span> 
                          <span class="n">embed_l2</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> 
                          <span class="n">layer_l2</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> 
                          <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>  <span class="c1"># set to 0.01 if batch normalization is disable</span>
                          <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                          <span class="n">show_step</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                          <span class="n">MODEL_DIR</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;model/&quot;</span><span class="p">),</span>
                          <span class="n">SUMMARIES_DIR</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="s2">&quot;summary/&quot;</span><span class="p">),</span>
                          <span class="n">user_vocab</span><span class="o">=</span><span class="n">user_vocab</span><span class="p">,</span>
                          <span class="n">item_vocab</span><span class="o">=</span><span class="n">item_vocab</span><span class="p">,</span>
                          <span class="n">cate_vocab</span><span class="o">=</span><span class="n">cate_vocab</span><span class="p">,</span>
                          <span class="n">need_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">train_num_ngs</span><span class="o">=</span><span class="n">train_num_ngs</span><span class="p">,</span> <span class="c1"># provides the number of negative instances for each positive instance for loss computation.</span>
            <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="create-data-loader">
<h4>1.2 Create data loader<a class="headerlink" href="#create-data-loader" title="Permalink to this headline">¶</a></h4>
<p>Designate a data iterator for the model. All our sequential models use SequentialIterator.
data format is introduced aboved.</p>
<p><br>Validation and testing data are files after negative sampling offline with the number of <code class="docutils literal notranslate"><span class="pre">&lt;num_ngs&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;test_num_ngs&gt;</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_creator</span> <span class="o">=</span> <span class="n">SequentialIterator</span>
<span class="c1">#### uncomment this for the NextItNet model, because it needs a special data iterator for training</span>
<span class="c1">#input_creator = NextItNetIterator</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="create-model">
<h2>2. Create model<a class="headerlink" href="#create-model" title="Permalink to this headline">¶</a></h2>
<p>When both hyper-parameters and data iterator are ready, we can create a model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SeqModel</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">input_creator</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>

<span class="c1">## sometimes we don&#39;t want to train a model from scratch</span>
<span class="c1">## then we can load a pre-trained model like this: </span>
<span class="c1">#model.load_model(r&#39;your_model_path&#39;)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s see what is the model’s performance at this point (without starting training):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># test_num_ngs is the number of negative lines after each positive line in your test_file</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">run_eval</span><span class="p">(</span><span class="n">test_file</span><span class="p">,</span> <span class="n">num_ngs</span><span class="o">=</span><span class="n">test_num_ngs</span><span class="p">))</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;auc&#39;: 0.4857, &#39;logloss&#39;: 0.6931, &#39;mean_mrr&#39;: 0.2665, &#39;ndcg@2&#39;: 0.1357, &#39;ndcg@4&#39;: 0.2186, &#39;ndcg@6&#39;: 0.2905, &#39;group_auc&#39;: 0.4849}
</pre></div>
</div>
</div>
</div>
<p>AUC=0.5 is a state of random guess. We can see that before training, the model behaves like random guessing.</p>
<div class="section" id="train-model">
<h3>2.1 Train model<a class="headerlink" href="#train-model" title="Permalink to this headline">¶</a></h3>
<p>Next we want to train the model on a training set, and check the performance on a validation dataset. Training the model is as simple as a function call:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">Timer</span><span class="p">()</span> <span class="k">as</span> <span class="n">train_time</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_file</span><span class="p">,</span> <span class="n">valid_file</span><span class="p">,</span> <span class="n">valid_num_ngs</span><span class="o">=</span><span class="n">valid_num_ngs</span><span class="p">)</span> 

<span class="c1"># valid_num_ngs is the number of negative lines after each positive line in your valid_file </span>
<span class="c1"># we will evaluate the performance of model on valid_file every epoch</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Time cost for training is </span><span class="si">{0:.2f}</span><span class="s1"> mins&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_time</span><span class="o">.</span><span class="n">interval</span><span class="o">/</span><span class="mf">60.0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>step 20 , total_loss: 1.6078, data_loss: 1.6078
step 40 , total_loss: 1.6054, data_loss: 1.6054
eval valid at epoch 1: auc:0.4975,logloss:0.6929,mean_mrr:0.4592,ndcg@2:0.3292,ndcg@4:0.5125,ndcg@6:0.5915,group_auc:0.4994
step 20 , total_loss: 1.5786, data_loss: 1.5786
step 40 , total_loss: 1.4193, data_loss: 1.4193
eval valid at epoch 2: auc:0.6486,logloss:0.6946,mean_mrr:0.5567,ndcg@2:0.472,ndcg@4:0.6292,ndcg@6:0.6669,group_auc:0.6363
step 20 , total_loss: 1.3229, data_loss: 1.3229
step 40 , total_loss: 1.3079, data_loss: 1.3079
eval valid at epoch 3: auc:0.6887,logloss:0.8454,mean_mrr:0.6032,ndcg@2:0.537,ndcg@4:0.6705,ndcg@6:0.7022,group_auc:0.683
step 20 , total_loss: 1.3521, data_loss: 1.3521
step 40 , total_loss: 1.2250, data_loss: 1.2250
eval valid at epoch 4: auc:0.6978,logloss:0.7005,mean_mrr:0.6236,ndcg@2:0.5622,ndcg@4:0.6881,ndcg@6:0.7175,group_auc:0.699
step 20 , total_loss: 1.2826, data_loss: 1.2826
step 40 , total_loss: 1.2795, data_loss: 1.2795
eval valid at epoch 5: auc:0.7152,logloss:0.6695,mean_mrr:0.6382,ndcg@2:0.582,ndcg@4:0.7009,ndcg@6:0.7286,group_auc:0.7139
step 20 , total_loss: 1.2214, data_loss: 1.2214
step 40 , total_loss: 1.2521, data_loss: 1.2521
eval valid at epoch 6: auc:0.722,logloss:0.6141,mean_mrr:0.637,ndcg@2:0.5796,ndcg@4:0.6993,ndcg@6:0.7276,group_auc:0.7116
step 20 , total_loss: 1.1884, data_loss: 1.1884
step 40 , total_loss: 1.1957, data_loss: 1.1957
eval valid at epoch 7: auc:0.7287,logloss:0.6183,mean_mrr:0.6417,ndcg@2:0.5875,ndcg@4:0.7031,ndcg@6:0.7312,group_auc:0.7167
step 20 , total_loss: 1.1779, data_loss: 1.1779
step 40 , total_loss: 1.1616, data_loss: 1.1616
eval valid at epoch 8: auc:0.7342,logloss:0.6584,mean_mrr:0.6538,ndcg@2:0.6006,ndcg@4:0.7121,ndcg@6:0.7402,group_auc:0.7248
step 20 , total_loss: 1.1299, data_loss: 1.1299
step 40 , total_loss: 1.2055, data_loss: 1.2055
eval valid at epoch 9: auc:0.7324,logloss:0.6268,mean_mrr:0.6541,ndcg@2:0.5981,ndcg@4:0.7129,ndcg@6:0.7404,group_auc:0.7239
step 20 , total_loss: 1.1927, data_loss: 1.1927
step 40 , total_loss: 1.1909, data_loss: 1.1909
eval valid at epoch 10: auc:0.7369,logloss:0.6122,mean_mrr:0.6611,ndcg@2:0.6087,ndcg@4:0.7181,ndcg@6:0.7457,group_auc:0.731
[(1, {&#39;auc&#39;: 0.4975, &#39;logloss&#39;: 0.6929, &#39;mean_mrr&#39;: 0.4592, &#39;ndcg@2&#39;: 0.3292, &#39;ndcg@4&#39;: 0.5125, &#39;ndcg@6&#39;: 0.5915, &#39;group_auc&#39;: 0.4994}), (2, {&#39;auc&#39;: 0.6486, &#39;logloss&#39;: 0.6946, &#39;mean_mrr&#39;: 0.5567, &#39;ndcg@2&#39;: 0.472, &#39;ndcg@4&#39;: 0.6292, &#39;ndcg@6&#39;: 0.6669, &#39;group_auc&#39;: 0.6363}), (3, {&#39;auc&#39;: 0.6887, &#39;logloss&#39;: 0.8454, &#39;mean_mrr&#39;: 0.6032, &#39;ndcg@2&#39;: 0.537, &#39;ndcg@4&#39;: 0.6705, &#39;ndcg@6&#39;: 0.7022, &#39;group_auc&#39;: 0.683}), (4, {&#39;auc&#39;: 0.6978, &#39;logloss&#39;: 0.7005, &#39;mean_mrr&#39;: 0.6236, &#39;ndcg@2&#39;: 0.5622, &#39;ndcg@4&#39;: 0.6881, &#39;ndcg@6&#39;: 0.7175, &#39;group_auc&#39;: 0.699}), (5, {&#39;auc&#39;: 0.7152, &#39;logloss&#39;: 0.6695, &#39;mean_mrr&#39;: 0.6382, &#39;ndcg@2&#39;: 0.582, &#39;ndcg@4&#39;: 0.7009, &#39;ndcg@6&#39;: 0.7286, &#39;group_auc&#39;: 0.7139}), (6, {&#39;auc&#39;: 0.722, &#39;logloss&#39;: 0.6141, &#39;mean_mrr&#39;: 0.637, &#39;ndcg@2&#39;: 0.5796, &#39;ndcg@4&#39;: 0.6993, &#39;ndcg@6&#39;: 0.7276, &#39;group_auc&#39;: 0.7116}), (7, {&#39;auc&#39;: 0.7287, &#39;logloss&#39;: 0.6183, &#39;mean_mrr&#39;: 0.6417, &#39;ndcg@2&#39;: 0.5875, &#39;ndcg@4&#39;: 0.7031, &#39;ndcg@6&#39;: 0.7312, &#39;group_auc&#39;: 0.7167}), (8, {&#39;auc&#39;: 0.7342, &#39;logloss&#39;: 0.6584, &#39;mean_mrr&#39;: 0.6538, &#39;ndcg@2&#39;: 0.6006, &#39;ndcg@4&#39;: 0.7121, &#39;ndcg@6&#39;: 0.7402, &#39;group_auc&#39;: 0.7248}), (9, {&#39;auc&#39;: 0.7324, &#39;logloss&#39;: 0.6268, &#39;mean_mrr&#39;: 0.6541, &#39;ndcg@2&#39;: 0.5981, &#39;ndcg@4&#39;: 0.7129, &#39;ndcg@6&#39;: 0.7404, &#39;group_auc&#39;: 0.7239}), (10, {&#39;auc&#39;: 0.7369, &#39;logloss&#39;: 0.6122, &#39;mean_mrr&#39;: 0.6611, &#39;ndcg@2&#39;: 0.6087, &#39;ndcg@4&#39;: 0.7181, &#39;ndcg@6&#39;: 0.7457, &#39;group_auc&#39;: 0.731})]
best epoch: 10
Time cost for training is 3.22 mins
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="evaluate-model">
<h3>2.2  Evaluate model<a class="headerlink" href="#evaluate-model" title="Permalink to this headline">¶</a></h3>
<p>Again, let’s see what is the model’s performance now (after training):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res_syn</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">run_eval</span><span class="p">(</span><span class="n">test_file</span><span class="p">,</span> <span class="n">num_ngs</span><span class="o">=</span><span class="n">test_num_ngs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res_syn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;auc&#39;: 0.7174, &#39;logloss&#39;: 0.6149, &#39;mean_mrr&#39;: 0.4835, &#39;ndcg@2&#39;: 0.3939, &#39;ndcg@4&#39;: 0.4982, &#39;ndcg@6&#39;: 0.5503, &#39;group_auc&#39;: 0.7073}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sb</span><span class="o">.</span><span class="n">glue</span><span class="p">(</span><span class="s2">&quot;res_syn&quot;</span><span class="p">,</span> <span class="n">res_syn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If we want to get the full prediction scores rather than evaluation metrics, we can do this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_file</span><span class="p">,</span> <span class="n">output_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The data was downloaded in tmpdir folder. You can delete them manually if you do not need them any more.</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="running-models-with-large-dataset">
<h3>2.3  Running models with large dataset<a class="headerlink" href="#running-models-with-large-dataset" title="Permalink to this headline">¶</a></h3>
<p>Here are performances using the whole amazon dataset among popular sequential models with 1,697,533 positive instances.
<br>Settings for reproducing the results:
<br><code class="docutils literal notranslate"><span class="pre">learning_rate=0.001,</span> <span class="pre">dropout=0.3,</span> <span class="pre">item_embedding_dim=32,</span> <span class="pre">cate_embedding_dim=8,</span> <span class="pre">l2_norm=0,</span> <span class="pre">batch_size=400,</span>&#160; <span class="pre">train_num_ngs=4,</span> <span class="pre">valid_num_ngs=4,</span> <span class="pre">test_num_ngs=49</span></code></p>
<p>We compare the running time with CPU only and with GPU on the larger dataset. It appears that GPU can significantly accelerate the training. Hardware specification for running the large dataset:
<br>GPU: Tesla P100-PCIE-16GB
<br>CPU: 6 cores Intel(R) Xeon(R) CPU E5-2690 v4 &#64; 2.60GHz</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Models</p></th>
<th class="text-align:center head"><p>AUC</p></th>
<th class="text-align:center head"><p>g-AUC</p></th>
<th class="text-align:center head"><p>NDCG&#64;2</p></th>
<th class="text-align:center head"><p>NDCG&#64;10</p></th>
<th class="text-align:center head"><p>seconds per epoch on GPU</p></th>
<th class="text-align:center head"><p>seconds per epoch on CPU</p></th>
<th class="text-align:left head"><p>config</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>A2SVD</p></td>
<td class="text-align:center"><p>0.8251</p></td>
<td class="text-align:center"><p>0.8178</p></td>
<td class="text-align:center"><p>0.2922</p></td>
<td class="text-align:center"><p>0.4264</p></td>
<td class="text-align:center"><p>249.5</p></td>
<td class="text-align:center"><p>440.0</p></td>
<td class="text-align:left"><p>N/A</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>GRU4Rec</p></td>
<td class="text-align:center"><p>0.8411</p></td>
<td class="text-align:center"><p>0.8332</p></td>
<td class="text-align:center"><p>0.3213</p></td>
<td class="text-align:center"><p>0.4547</p></td>
<td class="text-align:center"><p>439.0</p></td>
<td class="text-align:center"><p>4285.0</p></td>
<td class="text-align:left"><p>max_seq_length=50, hidden_size=40</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Caser</p></td>
<td class="text-align:center"><p>0.8244</p></td>
<td class="text-align:center"><p>0.8171</p></td>
<td class="text-align:center"><p>0.283</p></td>
<td class="text-align:center"><p>0.4194</p></td>
<td class="text-align:center"><p>314.3</p></td>
<td class="text-align:center"><p>5369.9</p></td>
<td class="text-align:left"><p>T=1, n_v=128, n_h=128, L=3, min_seq_length=5</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>SLi_Rec</p></td>
<td class="text-align:center"><p>0.8631</p></td>
<td class="text-align:center"><p>0.8519</p></td>
<td class="text-align:center"><p>0.3491</p></td>
<td class="text-align:center"><p>0.4842</p></td>
<td class="text-align:center"><p>549.6</p></td>
<td class="text-align:center"><p>5014.0</p></td>
<td class="text-align:left"><p>attention_size=40, max_seq_length=50, hidden_size=40</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>NextItNet*</p></td>
<td class="text-align:center"><p>0.6793</p></td>
<td class="text-align:center"><p>0.6769</p></td>
<td class="text-align:center"><p>0.0602</p></td>
<td class="text-align:center"><p>0.1733</p></td>
<td class="text-align:center"><p>112.0</p></td>
<td class="text-align:center"><p>214.5</p></td>
<td class="text-align:left"><p>min_seq_length=3, dilations=[1,2,4,1,2,4], kernel_size=3</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>SUM</p></td>
<td class="text-align:center"><p>0.8481</p></td>
<td class="text-align:center"><p>0.8406</p></td>
<td class="text-align:center"><p>0.3394</p></td>
<td class="text-align:center"><p>0.4774</p></td>
<td class="text-align:center"><p>1005.0</p></td>
<td class="text-align:center"><p>9427.0</p></td>
<td class="text-align:left"><p>hidden_size=40, slots=4, dropout=0</p></td>
</tr>
</tbody>
</table>
<p>Note 1: The five models are grid searched with a coarse granularity and the results are for reference only.
<br>Note 2: NextItNet model requires a dataset with strong sequence property, but the Amazon dataset used in this notebook does not meet that requirement, so NextItNet Model may not performance good. If you wish to use other datasets with strong sequence property, NextItNet is recommended.
<br>Note 3: Time cost of NextItNet Model is significantly shorter than other models because it doesn’t need a history expanding of training data.</p>
</div>
</div>
<div class="section" id="online-serving">
<h2>3. Online serving<a class="headerlink" href="#online-serving" title="Permalink to this headline">¶</a></h2>
<p>In this section, we provide a simple example to illustrate how we can use the trained model to serve for production demand.</p>
<p>Suppose we are in a new session. First let’s load a previous trained model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_best_trained</span> <span class="o">=</span> <span class="n">SeqModel</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">input_creator</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">RANDOM_SEED</span><span class="p">)</span>
<span class="n">path_best_trained</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">MODEL_DIR</span><span class="p">,</span> <span class="s2">&quot;best_model&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loading saved model in </span><span class="si">{0}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path_best_trained</span><span class="p">))</span>
<span class="n">model_best_trained</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">path_best_trained</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>loading saved model in ../../tests/resources/deeprec/slirec/model/best_model
INFO:tensorflow:Restoring parameters from ../../tests/resources/deeprec/slirec/model/best_model
</pre></div>
</div>
</div>
</div>
<p>Let’s see if we load the model correctly. The testing metrics should be close to the numbers we have in the training stage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_best_trained</span><span class="o">.</span><span class="n">run_eval</span><span class="p">(</span><span class="n">test_file</span><span class="p">,</span> <span class="n">num_ngs</span><span class="o">=</span><span class="n">test_num_ngs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;auc&#39;: 0.7249,
 &#39;logloss&#39;: 0.5924,
 &#39;mean_mrr&#39;: 0.4946,
 &#39;ndcg@2&#39;: 0.4075,
 &#39;ndcg@4&#39;: 0.5107,
 &#39;ndcg@6&#39;: 0.5607,
 &#39;group_auc&#39;: 0.7133}
</pre></div>
</div>
</div>
</div>
<p>And we make predictions using this model. In the next step, we will make predictions using a serving model. Then we can check if the two result files are consistent.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_best_trained</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_file</span><span class="p">,</span> <span class="n">output_file</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;recommenders.models.deeprec.models.sequential.sli_rec.SLI_RECModel at 0x7f2da0326e80&gt;
</pre></div>
</div>
</div>
</div>
<p>Exciting. Now let’s start our quick journey of online serving.</p>
<p>For efficient and flexible serving, usually we only keep the necessary computation nodes and froze the TF model to a single pb file, so that we can easily compute scores with this unified pb file in both Python or Java:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">model_best_trained</span><span class="o">.</span><span class="n">sess</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">graph_def</span> <span class="o">=</span> <span class="n">model_best_trained</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">()</span>
    <span class="n">output_graph_def</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">graph_util</span><span class="o">.</span><span class="n">convert_variables_to_constants</span><span class="p">(</span>
        <span class="n">sess</span><span class="p">,</span>
        <span class="n">graph_def</span><span class="p">,</span>
        <span class="p">[</span><span class="s2">&quot;pred&quot;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">outfilepath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">MODEL_DIR</span><span class="p">,</span> <span class="s2">&quot;serving_model.pb&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">outfilepath</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">output_graph_def</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>The serving logic is as simple as feeding the feature values to the corresponding input nodes, and fetch the score from the output node.</p>
<p>In our model, input nodes are some placeholders and control variables (such as is_training, layer_keeps). We can get the nodes by their name:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LoadFrozedPredModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/pred:0&#39;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">items</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/items:0&#39;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">cates</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/cates:0&#39;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">item_history</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/item_history:0&#39;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">item_cate_history</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/item_cate_history:0&#39;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/mask:0&#39;</span><span class="p">)</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">time_from_first_action</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/time_from_first_action:0&#39;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">time_to_now</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/time_to_now:0&#39;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_keeps</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/layer_keeps:0&#39;</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">is_training</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;import/is_training:0&#39;</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">infer_as_serving</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">infile</span><span class="p">,</span> <span class="n">outfile</span><span class="p">,</span> <span class="n">hparams</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">sess</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">batch_data_input</span> <span class="ow">in</span> <span class="n">iterator</span><span class="o">.</span><span class="n">load_data_from_file</span><span class="p">(</span><span class="n">infile</span><span class="p">,</span> <span class="n">batch_num_ngs</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">batch_data_input</span><span class="p">:</span>
            <span class="n">feed_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">model</span><span class="o">.</span><span class="n">layer_keeps</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                <span class="n">model</span><span class="o">.</span><span class="n">is_training</span><span class="p">:</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">model</span><span class="o">.</span><span class="n">items</span><span class="p">:</span> <span class="n">batch_data_input</span><span class="p">[</span><span class="n">iterator</span><span class="o">.</span><span class="n">items</span><span class="p">],</span>
                <span class="n">model</span><span class="o">.</span><span class="n">cates</span><span class="p">:</span> <span class="n">batch_data_input</span><span class="p">[</span><span class="n">iterator</span><span class="o">.</span><span class="n">cates</span><span class="p">],</span>
                <span class="n">model</span><span class="o">.</span><span class="n">item_history</span><span class="p">:</span> <span class="n">batch_data_input</span><span class="p">[</span><span class="n">iterator</span><span class="o">.</span><span class="n">item_history</span><span class="p">],</span>
                <span class="n">model</span><span class="o">.</span><span class="n">item_cate_history</span><span class="p">:</span> <span class="n">batch_data_input</span><span class="p">[</span><span class="n">iterator</span><span class="o">.</span><span class="n">item_cate_history</span><span class="p">],</span>
                <span class="n">model</span><span class="o">.</span><span class="n">mask</span><span class="p">:</span> <span class="n">batch_data_input</span><span class="p">[</span><span class="n">iterator</span><span class="o">.</span><span class="n">mask</span><span class="p">],</span>
                <span class="n">model</span><span class="o">.</span><span class="n">time_from_first_action</span><span class="p">:</span> <span class="n">batch_data_input</span><span class="p">[</span><span class="n">iterator</span><span class="o">.</span><span class="n">time_from_first_action</span><span class="p">],</span>
                <span class="n">model</span><span class="o">.</span><span class="n">time_to_now</span><span class="p">:</span> <span class="n">batch_data_input</span><span class="p">[</span><span class="n">iterator</span><span class="o">.</span><span class="n">time_to_now</span><span class="p">]</span>
            <span class="p">}</span>
            <span class="n">step_pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed_dict</span><span class="p">)</span>
            <span class="n">preds</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">step_pred</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">outfile</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">wt</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">preds</span><span class="p">:</span>
            <span class="n">wt</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{0}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">line</span><span class="p">))</span>
            
</pre></div>
</div>
</div>
</div>
<p>Here is the main pipeline for inferring in an online serving manner. You can compare the ‘output_serving.txt’ with ‘output.txt’ to see if the results are consistent.</p>
<p>The input file format is the same as introduced in Section 1 ‘Input data format’. In serving stage, since we do not need a groundtrue lable, so for the label column, you can simply place any number like a zero. The iterator will parse the input file and convert into the required format for model’s feed_dictionary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">hparams</span><span class="o">.</span><span class="n">MODEL_DIR</span><span class="p">,</span> <span class="s2">&quot;serving_model.pb&quot;</span><span class="p">),</span>
        <span class="s1">&#39;rb&#39;</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">,</span> <span class="n">G</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">graph_def_optimized</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">GraphDef</span><span class="p">()</span>
    <span class="n">graph_def_optimized</span><span class="o">.</span><span class="n">ParseFromString</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
    
    <span class="c1">####  uncomment this line if you want to check what conent is included in the graph</span>
    <span class="c1">#print(&#39;graph_def_optimized = &#39; + str(graph_def_optimized))</span>


<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">G</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">import_graph_def</span><span class="p">(</span><span class="n">graph_def_optimized</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">LoadFrozedPredModel</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
    
    <span class="n">serving_output_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;output_serving.txt&#39;</span><span class="p">)</span>  
    <span class="n">iterator</span> <span class="o">=</span> <span class="n">input_creator</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">())</span>
    <span class="n">infer_as_serving</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_file</span><span class="p">,</span> <span class="n">serving_output_file</span><span class="p">,</span> <span class="n">hparams</span><span class="p">,</span> <span class="n">iterator</span><span class="p">,</span> <span class="n">sess</span><span class="p">)</span>
    
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h2>
<p>[1] Zeping Yu, Jianxun Lian, Ahmad Mahmoody, Gongshen Liu, Xing Xie. Adaptive User Modeling with Long and Short-Term Preferences for Personailzed Recommendation. In Proceedings of the 28th International Joint Conferences on Artificial Intelligence, IJCAI’19, Pages 4213-4219. AAAI Press, 2019.</p>
<p>[2] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, Domonkos Tikk. Session-based Recommendations with Recurrent Neural Networks. ICLR (Poster) 2016</p>
<p>[3] Tang, Jiaxi, and Ke Wang. Personalized top-n sequential recommendation via convolutional sequence embedding. Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. ACM, 2018.</p>
<p>[4] Yuan, F., Karatzoglou, A., Arapakis, I., Jose, J. M., &amp; He, X. A Simple Convolutional Generative Network for Next Item Recommendation. WSDM, 2019</p>
<p>[5] Lian, J., Batal, I., Liu, Z., Soni, A., Kang, E. Y., Wang, Y., &amp; Xie, X. Multi-Interest-Aware User Modeling for Large-Scale Sequential Recommendations. (2021) arXiv preprint arXiv:2102.09211.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "reco_gpu"
        },
        kernelOptions: {
            kernelName: "reco_gpu",
            path: "./examples/00_quick_start"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'reco_gpu'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By The Jupyter Book community<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>